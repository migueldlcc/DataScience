{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates interpolation data for incidents between the specified\n",
    "start_date and end_date, and saves it as csv file in the folder:\n",
    "/fromIncidentToInterpolationData/incidentInterpolationData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presets, agreed upon for all diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_incident = 3000\n",
    "t_incident = 60\n",
    "time_recording_before_incident = 60\n",
    "time_recording_after_incident = 420 #7hours\n",
    "\n",
    "# the filename for the speedflow data \n",
    "file_name = \"/Users/vree/Documents/UTwente/Masters UTwente/Data Science/DM Project/Speed-flow/Maart/intensiteit-snelheid-rotterdam-15-21-Maart/intensiteit-snelheid-rotterdam-15-21-Maart.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "presets for current run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter dates between 15th of March 2020 and 21th of March 2020\n",
    "start_date = '2020-03-15'\n",
    "end_date = '2020-03-21'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(266, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>starttijd</th>\n",
       "      <th>type</th>\n",
       "      <th>gedetailleerd_type</th>\n",
       "      <th>primaire_locatie_lengtegraad</th>\n",
       "      <th>primaire_locatie_breedtegraad</th>\n",
       "      <th>segment</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RWS02_0000157188_157188</td>\n",
       "      <td>2020-03-01 08:38:28</td>\n",
       "      <td>vehicle_obstruction</td>\n",
       "      <td>emergencyVehicle</td>\n",
       "      <td>4.366420</td>\n",
       "      <td>51.920952</td>\n",
       "      <td>north</td>\n",
       "      <td>{'RWS01_MONIBAS_0041hrl0706ra': 0.022954588858...</td>\n",
       "      <td>{'GEO0K_K_RWSTI357132': 0.16579609461072695}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RWS02_0000157197_157197</td>\n",
       "      <td>2020-03-01 10:00:57</td>\n",
       "      <td>vehicle_obstruction</td>\n",
       "      <td>emergencyVehicle</td>\n",
       "      <td>4.432840</td>\n",
       "      <td>51.928864</td>\n",
       "      <td>west-east</td>\n",
       "      <td>{'RWS01_MONIBAS_0201hrr0284ra': 0.094239550154...</td>\n",
       "      <td>{'RWS01_MONIBAS_0201hrr0285ra': 0.065785586736...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RWS02_0000157269_157269</td>\n",
       "      <td>2020-03-01 13:21:58</td>\n",
       "      <td>vehicle_obstruction</td>\n",
       "      <td>emergencyVehicle</td>\n",
       "      <td>4.456025</td>\n",
       "      <td>51.864422</td>\n",
       "      <td>east-west</td>\n",
       "      <td>{'RWS01_MONIBAS_0150vwy0557ra': 0.249505010285...</td>\n",
       "      <td>{'RWS01_MONIBAS_0150vwy0553ra': 0.229508095798...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RWS03_816372_1</td>\n",
       "      <td>2020-03-01 15:19:57</td>\n",
       "      <td>vehicle_obstruction</td>\n",
       "      <td>brokenDownVehicle</td>\n",
       "      <td>4.538568</td>\n",
       "      <td>51.909523</td>\n",
       "      <td>south</td>\n",
       "      <td>{'RWS01_MONIBAS_0160vwx0193ra': 0.896763594374...</td>\n",
       "      <td>{'RWS01_MONIBAS_0160vwx0202ra': 0.001663796286...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RWS02_0000157393_157393</td>\n",
       "      <td>2020-03-01 23:03:29</td>\n",
       "      <td>vehicle_obstruction</td>\n",
       "      <td>emergencyVehicle</td>\n",
       "      <td>4.439620</td>\n",
       "      <td>51.868599</td>\n",
       "      <td>east-west</td>\n",
       "      <td>{'RWS01_MONIBAS_0150vwy0544ra': 0.166980200322...</td>\n",
       "      <td>{'RWS01_MONIBAS_0150vwy0540ra': 0.210197772623...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id           starttijd                 type  \\\n",
       "0  RWS02_0000157188_157188 2020-03-01 08:38:28  vehicle_obstruction   \n",
       "1  RWS02_0000157197_157197 2020-03-01 10:00:57  vehicle_obstruction   \n",
       "2  RWS02_0000157269_157269 2020-03-01 13:21:58  vehicle_obstruction   \n",
       "3           RWS03_816372_1 2020-03-01 15:19:57  vehicle_obstruction   \n",
       "4  RWS02_0000157393_157393 2020-03-01 23:03:29  vehicle_obstruction   \n",
       "\n",
       "  gedetailleerd_type  primaire_locatie_lengtegraad  \\\n",
       "0   emergencyVehicle                      4.366420   \n",
       "1   emergencyVehicle                      4.432840   \n",
       "2   emergencyVehicle                      4.456025   \n",
       "3  brokenDownVehicle                      4.538568   \n",
       "4   emergencyVehicle                      4.439620   \n",
       "\n",
       "   primaire_locatie_breedtegraad    segment  \\\n",
       "0                      51.920952      north   \n",
       "1                      51.928864  west-east   \n",
       "2                      51.864422  east-west   \n",
       "3                      51.909523      south   \n",
       "4                      51.868599  east-west   \n",
       "\n",
       "                                              before  \\\n",
       "0  {'RWS01_MONIBAS_0041hrl0706ra': 0.022954588858...   \n",
       "1  {'RWS01_MONIBAS_0201hrr0284ra': 0.094239550154...   \n",
       "2  {'RWS01_MONIBAS_0150vwy0557ra': 0.249505010285...   \n",
       "3  {'RWS01_MONIBAS_0160vwx0193ra': 0.896763594374...   \n",
       "4  {'RWS01_MONIBAS_0150vwy0544ra': 0.166980200322...   \n",
       "\n",
       "                                               after  \n",
       "0       {'GEO0K_K_RWSTI357132': 0.16579609461072695}  \n",
       "1  {'RWS01_MONIBAS_0201hrr0285ra': 0.065785586736...  \n",
       "2  {'RWS01_MONIBAS_0150vwy0553ra': 0.229508095798...  \n",
       "3  {'RWS01_MONIBAS_0160vwx0202ra': 0.001663796286...  \n",
       "4  {'RWS01_MONIBAS_0150vwy0540ra': 0.210197772623...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver='postgresql'\n",
    "username='dab_ds23241a_223'\n",
    "dbname=username # it is the same as the username\n",
    "password='Bh6KFgcWazMMCPvZ'\n",
    "server='bronto.ewi.utwente.nl'\n",
    "port='5432'\n",
    "\n",
    "# Create an engine instance\n",
    "alchemy_engine = create_engine(f'{driver}://{username}:{password}@{server}:{port}/{dbname}')\n",
    "\n",
    "# Connect to PostgreSQL server\n",
    "db_connection = alchemy_engine.connect()\n",
    "\n",
    "# Read the data into a_df\n",
    "a_df = pd.read_sql(f\"select * from \\\"project\\\".\\\"Incidents_With_Cameras\\\"\", db_connection)\n",
    "\n",
    "# Check if 'before' and 'after' columns are already dictionaries\n",
    "if a_df['before'].apply(type).eq(dict).all() and a_df['after'].apply(type).eq(dict).all():\n",
    "    print('Columns are already dictionaries.')\n",
    "else:\n",
    "    # Convert the 'before' and 'after' columns from JSON strings back to dictionaries if they are not already\n",
    "    a_df['before'] = a_df['before'].apply(lambda x: json.loads(x) if isinstance(x, str) else x)\n",
    "    a_df['after'] = a_df['after'].apply(lambda x: json.loads(x) if isinstance(x, str) else x)\n",
    "# Close the database connection\n",
    "db_connection.close()\n",
    "print(a_df.shape)\n",
    "a_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter between the preset dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 9)\n"
     ]
    }
   ],
   "source": [
    "# filter between preset dates: start_date and end_date\n",
    "a_df = a_df[(a_df['starttijd'] >= start_date) & (a_df['starttijd'] <= end_date)]\n",
    "print(a_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns cameras and their true x for an incident\n",
    "#  so a list of camera ids and their x values\n",
    "def create_x_variable_for_incident_cameras(row):\n",
    "    locations_before = row['before']\n",
    "    locations_after = row['after']\n",
    "    \n",
    "    # create dataframe with distance before, where the row entry is a json with a key\n",
    "    # for camera id and the value is the distance\n",
    "    before_cameras_data = []\n",
    "    \n",
    "    before_cameras_data = [{'camera_id': key, 'x': x_incident - (value * 1000)} for key, value in locations_before.items()]\n",
    "    \n",
    "    before_cameras_x = pd.DataFrame(before_cameras_data)\n",
    "    \n",
    "    # create dataframe with distance after, where the row entry is a json with a key\n",
    "    # for camera id and the value is the distance\n",
    "    after_cameras_data = []\n",
    "    \n",
    "    after_cameras_data = [{'camera_id': key, 'x': x_incident + (value * 1000)} for key, value in locations_after.items()]\n",
    "        \n",
    "    after_cameras_x = pd.DataFrame(after_cameras_data)\n",
    "    df = pd.concat([before_cameras_x, after_cameras_x])\n",
    "    print(df.head(3))\n",
    "    return df\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# times must be delivered as pd.datetime\n",
    "def speed_flow_data_for_incident(camera_ids, start_time, end_time):\n",
    "    # read speed flow data in chunks of 10000 and filter on camera id and time\n",
    "    # only keep start_meetperiode, id_meetlocatie, gem_snelheid\n",
    "    \n",
    "    \n",
    "    chunksize = 10000\n",
    "    chunks = []\n",
    "    for chunk in pd.read_csv(file_name, chunksize=chunksize):\n",
    "        chunk = chunk[(chunk['id_meetlocatie'].isin(camera_ids)) & (pd.to_datetime(chunk['start_meetperiode']) >= start_time) & (pd.to_datetime(chunk['start_meetperiode']) <= end_time)]\n",
    "        chunk = chunk[['start_meetperiode', 'id_meetlocatie', 'gem_snelheid']]\n",
    "        chunks.append(chunk)\n",
    "    return pd.concat(chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the incident interpolation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incident_row = a_df.iloc[0]\n",
    "\n",
    "# cameras_x_df = create_x_variable_for_incident_cameras(incident_row)\n",
    "    \n",
    "# camera_ids = cameras_x_df['camera_id'].tolist()\n",
    "\n",
    "# incident_time = pd.to_datetime(incident_row['starttijd'])\n",
    "# start_time_for_diagram = incident_time - pd.Timedelta(minutes=time_recording_before_incident)\n",
    "# end_time_for_diagram = incident_time + pd.Timedelta(minutes=time_recording_after_incident)\n",
    "# # returns df with start_meetperiode, id_meetlocatie, gem_snelheid\n",
    "# speedflow_data = speed_flow_data_for_incident(camera_ids, start_time_for_diagram, end_time_for_diagram)\n",
    "\n",
    "# # let the start_meetperiode be the time in minutes since the incident\n",
    "# speedflow_data['start_meetperiode'] = (pd.to_datetime(speedflow_data['start_meetperiode']) - incident_time).dt.total_seconds() / 60.0\n",
    "\n",
    "# merged_data = pd.merge(cameras_x_df, speedflow_data, left_on='camera_id', right_on='id_meetlocatie')\n",
    "\n",
    "# # rename columns: x->x, gem_snelheid->v, start_meetperiode->t\n",
    "# merged_data = merged_data.rename(columns={'x': 'x', 'gem_snelheid': 'v', 'start_meetperiode': 't'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate duplicates where x and t are the same, and take the average of v\n",
    "def aggregate_data(data):\n",
    "    return data.groupby(['x', 't']).agg({'v': 'mean'}).reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     camera_id            x\n",
      "0  RWS01_MONIBAS_0201hrr0324ra  2799.197115\n",
      "1  RWS01_MONIBAS_0201hrr0322ra  2545.692751\n",
      "2  RWS01_MONIBAS_0201hrr0319ra  2237.016259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c0/2gmfm5qd4tl9nzl882r0xr040000gn/T/ipykernel_43207/252438380.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk = chunk[(chunk['id_meetlocatie'].isin(camera_ids)) & (pd.to_datetime(chunk['start_meetperiode']) >= start_time) & (pd.to_datetime(chunk['start_meetperiode']) <= end_time)]\n",
      "/var/folders/c0/2gmfm5qd4tl9nzl882r0xr040000gn/T/ipykernel_43207/252438380.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk = chunk[(chunk['id_meetlocatie'].isin(camera_ids)) & (pd.to_datetime(chunk['start_meetperiode']) >= start_time) & (pd.to_datetime(chunk['start_meetperiode']) <= end_time)]\n",
      "/var/folders/c0/2gmfm5qd4tl9nzl882r0xr040000gn/T/ipykernel_43207/252438380.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk = chunk[(chunk['id_meetlocatie'].isin(camera_ids)) & (pd.to_datetime(chunk['start_meetperiode']) >= start_time) & (pd.to_datetime(chunk['start_meetperiode']) <= end_time)]\n",
      "/var/folders/c0/2gmfm5qd4tl9nzl882r0xr040000gn/T/ipykernel_43207/252438380.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk = chunk[(chunk['id_meetlocatie'].isin(camera_ids)) & (pd.to_datetime(chunk['start_meetperiode']) >= start_time) & (pd.to_datetime(chunk['start_meetperiode']) <= end_time)]\n",
      "/var/folders/c0/2gmfm5qd4tl9nzl882r0xr040000gn/T/ipykernel_43207/252438380.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk = chunk[(chunk['id_meetlocatie'].isin(camera_ids)) & (pd.to_datetime(chunk['start_meetperiode']) >= start_time) & (pd.to_datetime(chunk['start_meetperiode']) <= end_time)]\n",
      "/var/folders/c0/2gmfm5qd4tl9nzl882r0xr040000gn/T/ipykernel_43207/252438380.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk = chunk[(chunk['id_meetlocatie'].isin(camera_ids)) & (pd.to_datetime(chunk['start_meetperiode']) >= start_time) & (pd.to_datetime(chunk['start_meetperiode']) <= end_time)]\n",
      "/var/folders/c0/2gmfm5qd4tl9nzl882r0xr040000gn/T/ipykernel_43207/252438380.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk = chunk[(chunk['id_meetlocatie'].isin(camera_ids)) & (pd.to_datetime(chunk['start_meetperiode']) >= start_time) & (pd.to_datetime(chunk['start_meetperiode']) <= end_time)]\n",
      "/var/folders/c0/2gmfm5qd4tl9nzl882r0xr040000gn/T/ipykernel_43207/252438380.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk = chunk[(chunk['id_meetlocatie'].isin(camera_ids)) & (pd.to_datetime(chunk['start_meetperiode']) >= start_time) & (pd.to_datetime(chunk['start_meetperiode']) <= end_time)]\n",
      "/var/folders/c0/2gmfm5qd4tl9nzl882r0xr040000gn/T/ipykernel_43207/252438380.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk = chunk[(chunk['id_meetlocatie'].isin(camera_ids)) & (pd.to_datetime(chunk['start_meetperiode']) >= start_time) & (pd.to_datetime(chunk['start_meetperiode']) <= end_time)]\n",
      "/var/folders/c0/2gmfm5qd4tl9nzl882r0xr040000gn/T/ipykernel_43207/252438380.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk = chunk[(chunk['id_meetlocatie'].isin(camera_ids)) & (pd.to_datetime(chunk['start_meetperiode']) >= start_time) & (pd.to_datetime(chunk['start_meetperiode']) <= end_time)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed flow data for incident was:              start_meetperiode               id_meetlocatie  gem_snelheid\n",
      "54483752  2020-03-15 13:50:00  RWS01_MONIBAS_0201hrr0309ra          79.0\n",
      "54483753  2020-03-15 13:50:00  RWS01_MONIBAS_0201hrr0309ra          76.0\n",
      "54483754  2020-03-15 13:50:00  RWS01_MONIBAS_0201hrr0309ra          73.0\n",
      "54483755  2020-03-15 13:51:00  RWS01_MONIBAS_0201hrr0309ra          80.0\n",
      "54483756  2020-03-15 13:51:00  RWS01_MONIBAS_0201hrr0309ra          76.0\n"
     ]
    }
   ],
   "source": [
    "# retrieving a list of cameras and their x values\n",
    "def create_interpolation_data_for_incident(incident_row):\n",
    "    \n",
    "\n",
    "    cameras_x_df = create_x_variable_for_incident_cameras(incident_row)\n",
    "        \n",
    "    camera_ids = cameras_x_df['camera_id'].tolist()\n",
    "\n",
    "    incident_time = pd.to_datetime(incident_row['starttijd'])\n",
    "    start_time_for_diagram = incident_time - pd.Timedelta(minutes=time_recording_before_incident)\n",
    "    end_time_for_diagram = incident_time + pd.Timedelta(minutes=time_recording_after_incident)\n",
    "    # returns df with start_meetperiode, id_meetlocatie, gem_snelheid\n",
    "    speedflow_data = speed_flow_data_for_incident(camera_ids, start_time_for_diagram, end_time_for_diagram)\n",
    "\n",
    "    print(\"speed flow data for incident was: \", speedflow_data.head())\n",
    "\n",
    "    # let the start_meetperiode be the time in minutes since the incident\n",
    "    speedflow_data['start_meetperiode'] = ((pd.to_datetime(speedflow_data['start_meetperiode']) - incident_time).dt.total_seconds() / 60.0)+t_incident\n",
    "\n",
    "    merged_data = pd.merge(cameras_x_df, speedflow_data, left_on='camera_id', right_on='id_meetlocatie')\n",
    "\n",
    "    # rename columns: x->x, gem_snelheid->v, start_meetperiode->t\n",
    "    merged_data = merged_data.rename(columns={'x': 'x', 'gem_snelheid': 'v', 'start_meetperiode': 't'})\n",
    "    \n",
    "    return merged_data\n",
    "\n",
    "\n",
    "incident_row = a_df.iloc[0]\n",
    "incident_data = create_interpolation_data_for_incident(incident_row)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows incident data:  8640\n",
      "number of rows after removing negatives;  8633\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>t</th>\n",
       "      <th>v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1324.576342</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1324.576342</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>76.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1324.576342</td>\n",
       "      <td>2.533333</td>\n",
       "      <td>78.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1324.576342</td>\n",
       "      <td>3.533333</td>\n",
       "      <td>76.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1324.576342</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>78.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             x         t          v\n",
       "0  1324.576342  0.533333  76.000000\n",
       "1  1324.576342  1.533333  76.333333\n",
       "2  1324.576342  2.533333  78.333333\n",
       "3  1324.576342  3.533333  76.333333\n",
       "4  1324.576342  4.533333  78.666667"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only keep the columns x, v, t\n",
    "incident_data = incident_data[['x', 'v', 't']]\n",
    "\n",
    "# there's multiple measurements within a minute, which lead to duplicates for x, t . \n",
    "incident_data = aggregate_data(incident_data)\n",
    "# show number of rows incident data\n",
    "print('number of rows incident data: ', len(incident_data))\n",
    "\n",
    "incident_data_remove_negatives = incident_data[incident_data['v'] >= 0]\n",
    "# show number of rows after removing negatives\n",
    "print('number of rows after removing negatives; ', len(incident_data_remove_negatives))\n",
    "\n",
    "\n",
    "# write the data to a csv file in ./incidentInterpolationData/, use the incident id as filename\n",
    "incident_data_remove_negatives.to_csv(f'./incidentInterpolationData/{incident_row[\"id\"]}.csv', index=False)\n",
    "\n",
    "incident_data_remove_negatives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before removing duplicates:  (8640, 3)\n",
      "after removing duplicates:  (8640, 3)\n"
     ]
    }
   ],
   "source": [
    "print('before removing duplicates: ', incident_data.shape)\n",
    "\n",
    "# remove duplicates for x and t \n",
    "no_duplicates = incident_data.drop_duplicates(subset=['x', 't'])\n",
    "\n",
    "print('after removing duplicates: ', no_duplicates.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
